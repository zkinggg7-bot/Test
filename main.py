import requests
from bs4 import BeautifulSoup
import os
import time

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
BASE_URL = "https://rewayat.club/novel/you-are-running-30000-simulations-a-day-trying-to-stay-healthy-or-what/"
TOTAL_CHAPTERS = 5  # Ù„ØºØ±Ø¶ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø¹Ù„Ù‰ Railway Ø³Ù†ÙƒØªÙÙŠ Ø¨Ù€ 5 ÙØµÙˆÙ„
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
}

def fetch_chapter(chapter_num):
    url = f"{BASE_URL}{chapter_num}"
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
            title_tag = soup.find('div', class_='v-card__subtitle')
            chapter_title = title_tag.get_text(strip=True) if title_tag else f"Chapter {chapter_num}"
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            paragraphs = soup.find_all('p')
            clean_paragraphs = [p.get_text(strip=True) for p in paragraphs if len(p.get_text()) > 30]
            content = "\n\n".join(clean_paragraphs)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„Ù€ Logs Ù„ÙƒÙŠ ØªØ±Ø§Ù‡Ø§ ÙÙŠ Railway
            print(f"âœ… ØªÙ… Ø³Ø­Ø¨ Ø§Ù„ÙØµÙ„ {chapter_num}: {chapter_title}")
            print(f"ğŸ“ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù†Øµ: {content[:100]}...") # Ù†Ø·Ø¨Ø¹ Ø£ÙˆÙ„ 100 Ø­Ø±Ù Ù„Ù„ØªØ£ÙƒØ¯
            print("-" * 20)
            
        else:
            print(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙØµÙ„ {chapter_num} - Ø±Ù…Ø² Ø§Ù„Ø®Ø·Ø£: {response.status_code}")
            
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØµÙ„ {chapter_num}: {str(e)}")

if __name__ == "__main__":
    print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø¹Ù„Ù‰ Railway...")
    for i in range(1, TOTAL_CHAPTERS + 1):
        fetch_chapter(i)
        time.sleep(2)
    print("âœ¨ Ø§Ù†ØªÙ‡Øª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø¨Ù†Ø¬Ø§Ø­!")
